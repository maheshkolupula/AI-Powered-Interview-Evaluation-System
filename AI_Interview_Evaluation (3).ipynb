{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60dd6f92-8f6f-4103-b0ff-540d283cc1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instructions:\n",
      "üéôÔ∏è Speak your answers naturally. The system records automatically.\n",
      "‚è±Ô∏è If you stay silent for 10 seconds or press 'q', it moves to next question.\n",
      "üö™ Press 'Esc' anytime to exit.\n",
      "\n",
      "Gemini configured.\n",
      "Loading Whisper model: medium\n",
      "Whisper loaded.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your name:  Mahesh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome Mahesh! Please upload your resume.\n",
      "Resume uploaded.\n",
      "\n",
      "\n",
      "Question 1/10: Introduce yourself.\n",
      "Answer: Good morning, this is Mahesh and I am from Warangal. Thank you.\n",
      "Feedback: Nice to meet you, Mahesh.\n",
      "\n",
      "Question 2/10: Explain how you handled imbalanced classes in a previous ML project\n",
      "Answer: Yeah, I used one technique that is SMOTE technique which is used to imbalance data set to balance. Thank you.\n",
      "Feedback: Great job using SMOTE to address the class imbalance! It's a valuable technique to know.\n",
      "\n",
      "Question 3/10: Explain a time you deployed a machine learning model and the challenges faced\n",
      "Answer: Yeah, I usually like and don't know about this answer, sorry.\n",
      "Feedback: Thanks for sharing! Getting started is the hardest part. Keep thinking about your experiences!\n",
      "\n",
      "Question 4/10: Explain how you optimized your Naive Bayes spam detection model for deployment\n",
      "Answer: First, I load the data. Second step is tokenization. That means the whole corpus or sentence are breaking down into parts. I mean tokens like words. And third step is test cleaning. In the test cleaning to remove punctuation, remove stop words and stemming or lemmatization I used. After that vectorization. Then I used count vectorization. First of all, vectorization means to convert text into numerical because model cannot understand the text data. So we can convert the text to numerical. Fifth point is we apply the NLP technique models like navabar's algorithm.\n",
      "Feedback: Great explanation of your process! You clearly understand the steps involved in preparing text data for Naive Bayes.\n",
      "\n",
      "Question 5/10: Explain the Transformer architecture used in your machine translation project\n",
      "Answer: First of all, I there are transformer have two blocks, encoder and decoder block. I pass the message to the encoder block that is inside input side. I pass the input text and pre-processing that test and first it converts into token IDs. Later it converts the vector embedding. Based on the vector embedding, it converts one mechanism that is self-attention mechanism. It gives the relation between the words. So it converts the again we will give the output input to the decoder and deep coder is converted into our translate original translator means suppose I translate English to Telugu like how are you if the words are split into sentences split into words and that words are based on the self-attention mechanism it converts input to the decoder one one word is going to the decoder block using soft softmax or any ReLU functions like we convert into the another language that is Telugu.\n",
      "Feedback: Good start! You're hitting the key components of the encoder-decoder structure and attention mechanism.\n",
      "\n",
      "Question 6/10: Describe a project where you addressed overfitting in a machine learning model\n",
      "Answer: I assign house price prediction using linear regression. In that linear regression, first I upload the linear regression in that model, the overfitting problem is occur to reduce the overfitting problem using L1, L2 regularization techniques like Lasso Ridge. So with the help of the techniques to reduce the overfitting problem in that project. Thank you.\n",
      "Feedback: Great job tackling overfitting with L1 and L2 regularization! Your approach to improving model performance is clear.\n",
      "\n",
      "Question 7/10: How would you address concept drift in your deployed spam detection model?\n",
      "Answer: I don't know about this concept sorry\n",
      "Feedback: No problem! Thanks for letting me know. Keep exploring and learning!\n",
      "\n",
      "Question 8/10: Describe a time you overcame a significant obstacle in a machine learning project?\n",
      "Answer: Yeah, first of all, the time is more important than doing project any project like not only machine learning project any project that time efficiency is much more good. But in my project I did in my during three to four months back, I've faced a lot of problems I'm doing while I doing this project. But to overcome that project, I use a lot of techniques and I divide the whole project into sub parts and I do every day small small part and club the entire small parts into big one and one day the project is good and upload into real time deployment. Thank you.\n",
      "Feedback: Great job breaking down the project and tackling challenges head-on! Your perseverance paid off.\n",
      "\n",
      "Question 9/10: Describe your experience with CI/CD pipelines for deploying machine learning models\n",
      "Answer: I have no prior experience in deployment, but I know the CI CD pipelines. CI means continuous integration means which is when the train first we train the data model after that we test the model after then we that model will with the help of deliver we deploy into the productivity team whereas CD means continuous deployment with without any developer we can we should we can directly deploy into the productivity team thank you\n",
      "Feedback: Great start! Your understanding of CI/CD concepts is clear, and you're on the right track.\n",
      "\n",
      "Question 10/10: Describe a situation where your ML model significantly impacted a business outcome\n",
      "Answer: Yeah, it is based on the business only. The scientist concluded this ML algorithms. Why because the main purpose of ML means to increase the business and we find out the business insights and make decisions based on the business requirements. So first why it is impacted means ML algorithm they're trying to find the correct approach for new data set is if we give in. So it is also is doing refining in the algorithm. It creates model or equation that equation we use and the new data it will perform well the business is increased good. Let's check first accuracy then after we go through the time. Okay. Thank you.\n",
      "Feedback: Great explanation! You're clearly connecting the technical aspects to the business goals.\n",
      "\n",
      "Interview Completed.\n"
     ]
    }
   ],
   "source": [
    "import os, time, queue, re, contextlib, threading, sys\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import cv2, numpy as np\n",
    "\n",
    "try:\n",
    "    import whisper\n",
    "except:\n",
    "    whisper = None\n",
    "\n",
    "try:\n",
    "    import pyttsx3\n",
    "    TTS_AVAILABLE = True\n",
    "except:\n",
    "    pyttsx3 = None\n",
    "    TTS_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "    GEMINI_AVAILABLE = True\n",
    "except:\n",
    "    genai = None\n",
    "    GEMINI_AVAILABLE = False\n",
    "\n",
    "import PyPDF2, docx\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "\n",
    "print(\"Instructions:\")\n",
    "print(\"üéôÔ∏è Speak your answers naturally. The system records automatically.\")\n",
    "print(\"‚è±Ô∏è If you stay silent for 10 seconds or press 'q', it moves to next question.\")\n",
    "print(\"üö™ Press 'Esc' anytime to exit.\\n\")\n",
    "\n",
    "GEMINI_API_KEY = \"AIzaSyB3lGV8ju_l86r5_j465vTsXXW22yqddYY\"\n",
    "GENIE_MODEL_NAME = \"gemini-2.0-flash\"\n",
    "WHISPER_MODEL_NAME = \"medium\"\n",
    "\n",
    "AUDIO_FILENAME = \"candidate_answer.wav\"\n",
    "SAMPLE_RATE = 16000\n",
    "SILENCE_DURATION = 10.0\n",
    "SILENCE_THRESHOLD = 0.01\n",
    "WIN_W, WIN_H = 960, 540\n",
    "\n",
    "MAX_QUESTION_WORDS = 14\n",
    "TECH_QUESTIONS = 6\n",
    "HR_QUESTIONS = 3\n",
    "TOTAL_QUESTIONS = 1 + TECH_QUESTIONS + HR_QUESTIONS\n",
    "GEN_RETRY = 1 \n",
    "\n",
    "gen_model = None\n",
    "if GEMINI_AVAILABLE and GEMINI_API_KEY:\n",
    "    try:\n",
    "        genai.configure(api_key=GEMINI_API_KEY)\n",
    "        gen_model = genai.GenerativeModel(GENIE_MODEL_NAME)\n",
    "        print(\"Gemini configured.\")\n",
    "    except Exception as e:\n",
    "        print(\"Gemini init failed:\", e)\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_eye.xml\")\n",
    "smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_smile.xml\")\n",
    "\n",
    "whisper_model = None\n",
    "if whisper:\n",
    "    try:\n",
    "        print(\"Loading Whisper model:\", WHISPER_MODEL_NAME)\n",
    "        whisper_model = whisper.load_model(WHISPER_MODEL_NAME)\n",
    "        print(\"Whisper loaded.\")\n",
    "    except Exception as e:\n",
    "        print(\"Whisper load failed:\", e)\n",
    "\n",
    "def speak_blocking(text):\n",
    "    if not TTS_AVAILABLE:\n",
    "        print(\"AI:\", text)\n",
    "        return\n",
    "    try:\n",
    "        engine = pyttsx3.init()\n",
    "        engine.setProperty('rate', 170)\n",
    "        engine.say(str(text))\n",
    "        engine.runAndWait()\n",
    "    except Exception:\n",
    "        print(\"AI:\", text)\n",
    "\n",
    "def clean_text(t):\n",
    "    if t is None: return \"\"\n",
    "    t = re.sub(r'[^\\x00-\\x7F]+', ' ', str(t))\n",
    "    return re.sub(r'\\s+', ' ', t).strip()\n",
    "\n",
    "def wrap_text(text, max_chars=40):\n",
    "    if not text:\n",
    "        return [\"\"]\n",
    "    words, lines, cur = text.split(), [], \"\"\n",
    "    for w in words:\n",
    "        if len((cur + \" \" + w).strip()) <= max_chars:\n",
    "            cur = (cur + \" \" + w).strip()\n",
    "        else:\n",
    "            lines.append(cur)\n",
    "            cur = w\n",
    "    if cur: lines.append(cur)\n",
    "    return lines\n",
    "\n",
    "def extract_text_from_pdf(path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(path,\"rb\") as f:\n",
    "            r = PyPDF2.PdfReader(f)\n",
    "            for p in r.pages:\n",
    "                text += (p.extract_text() or \"\") + \"\\n\"\n",
    "    except:\n",
    "        pass\n",
    "    return clean_text(text)\n",
    "\n",
    "def extract_text_from_docx(path):\n",
    "    try:\n",
    "        d = docx.Document(path)\n",
    "        return clean_text(\"\\n\".join(p.text for p in d.paragraphs if p.text.strip()))\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def extract_text_from_file(path):\n",
    "    if not path: return \"\"\n",
    "    p = path.lower()\n",
    "    if p.endswith(\".pdf\"): return extract_text_from_pdf(path)\n",
    "    if p.endswith((\".doc\", \".docx\")): return extract_text_from_docx(path)\n",
    "    return \"\"\n",
    "\n",
    "def record_audio(stop_flag, filename=AUDIO_FILENAME):\n",
    "    q_audio, frames = queue.Queue(), []\n",
    "    last_loud = time.time()\n",
    "    speech_started = False\n",
    "\n",
    "    def _cb(indata, frames_count, time_info, status):\n",
    "        q_audio.put(indata.copy())\n",
    "\n",
    "    try:\n",
    "        with sd.InputStream(samplerate=SAMPLE_RATE, channels=1, callback=_cb):\n",
    "            while not stop_flag[\"next\"]:\n",
    "                try:\n",
    "                    data = q_audio.get(timeout=0.05)\n",
    "                    frames.append(data)\n",
    "                    rms = np.sqrt(np.mean(data**2))\n",
    "                    if rms > SILENCE_THRESHOLD:\n",
    "                        speech_started = True\n",
    "                        last_loud = time.time()\n",
    "                    elif speech_started and (time.time() - last_loud) > SILENCE_DURATION:\n",
    "                        stop_flag[\"next\"] = True\n",
    "                except queue.Empty:\n",
    "                    continue\n",
    "    except Exception as e:\n",
    "        print(\"Audio issue:\", e)\n",
    "\n",
    "    if frames:\n",
    "        audio = np.concatenate(frames, axis=0).flatten()\n",
    "        audio /= (np.max(np.abs(audio)) + 1e-9)\n",
    "        write(filename, SAMPLE_RATE, (audio * 32767).astype(np.int16))\n",
    "\n",
    "def transcribe_audio(filename=AUDIO_FILENAME):\n",
    "    if whisper_model is None or not os.path.exists(filename):\n",
    "        return \"\"\n",
    "    with contextlib.redirect_stdout(None):\n",
    "        try:\n",
    "            r = whisper_model.transcribe(filename, fp16=False, language=\"en\")\n",
    "            return clean_text(r.get(\"text\", \"\"))\n",
    "        except Exception as e:\n",
    "            print(\"Whisper error:\", e)\n",
    "            return \"\"\n",
    "\n",
    "def generate_next_question_background(jd_summary, resume_text, used_set, container, role):\n",
    "    jd_short = jd_summary if len(jd_summary) <= 800 else jd_summary[:800] + \"...\"\n",
    "    resume_short = resume_text if len(resume_text) <= 1200 else resume_text[:1200] + \"...\"\n",
    "    prompt = (\n",
    "        f\"Generate ONE {role} interview question (max {MAX_QUESTION_WORDS} words). \"\n",
    "        f\"JD: {jd_short}. Resume: {resume_short}. \"\n",
    "        f\"Only output the question. Avoid repeated or nonsensical questions. \"\n",
    "        f\"Previous questions: {list(used_set)}.\"\n",
    "    )\n",
    "    if gen_model is None:\n",
    "        container[0] = None\n",
    "        return\n",
    "    for _ in range(GEN_RETRY):\n",
    "        try:\n",
    "            r = gen_model.generate_content(prompt)\n",
    "            q = clean_text(r.text.split(\"\\n\")[0])\n",
    "            q = re.sub(r'^(question\\s*(\\d*|once|for you)\\s*[:\\-]?)', '', q, flags=re.I).strip()\n",
    "            q = q.split('.')[0].strip()\n",
    "            if q and q not in used_set:\n",
    "                used_set.add(q)\n",
    "                container[0] = q\n",
    "                return\n",
    "        except:\n",
    "            time.sleep(0.4)\n",
    "    container[0] = None\n",
    "\n",
    "def generate_feedback(question, answer):\n",
    "    if not gen_model:\n",
    "        return \"\"\n",
    "    prompt = (\n",
    "        f\"Provide a brief positive feedback or encouragement (max 20 words) \"\n",
    "        f\"on this answer: '{answer}' \"\n",
    "        f\"for the question: '{question}'. \"\n",
    "        f\"Avoid negative comments. Only output the feedback.\"\n",
    "    )\n",
    "    try:\n",
    "        r = gen_model.generate_content(prompt)\n",
    "        fb = clean_text(r.text.split(\"\\n\")[0])\n",
    "        return fb\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def run_interview():\n",
    "    candidate = input(\"Enter your name: \").strip() or \"Candidate\"\n",
    "    print(f\"\\nWelcome {candidate}! Please upload your resume.\")\n",
    "    speak_blocking(\"Please upload your resume.\")\n",
    "    Tk().withdraw()\n",
    "    resume_path = askopenfilename(title=\"Select Resume\", filetypes=[(\"Documents\",\"*.pdf *.docx\")])\n",
    "    resume_text = extract_text_from_file(resume_path) if resume_path else \"\"\n",
    "    print(\"Resume uploaded.\\n\")\n",
    "\n",
    "    jd_summary = (\n",
    "        \"We are looking for a motivated AI/ML Engineer with 1‚Äì3 years of hands-on experience \"\n",
    "        \"in building and deploying machine learning models.\"\n",
    "    )\n",
    "\n",
    "    used = set()\n",
    "    current_q = \"Introduce yourself.\"\n",
    "    used.add(current_q)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open webcam.\")\n",
    "        return\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "    cv2.namedWindow(\"AI Interview\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"AI Interview\", WIN_W, WIN_H)\n",
    "\n",
    "    all_answers = []\n",
    "\n",
    "    total_qs = TOTAL_QUESTIONS\n",
    "\n",
    "    for q_index in range(1, total_qs + 1):\n",
    "        print(f\"\\nQuestion {q_index}/{total_qs}: {current_q}\")\n",
    "        speak_blocking(f\"Question {q_index}. {current_q}\")\n",
    "\n",
    "        stop_flag = {\"next\": False}\n",
    "        rec_thread = threading.Thread(target=record_audio, args=(stop_flag,), daemon=True)\n",
    "        rec_thread.start()\n",
    "\n",
    "        wrapped = wrap_text(current_q, 40)\n",
    "\n",
    "        while not stop_flag[\"next\"]:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                time.sleep(0.01)\n",
    "                continue\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "            for (x, y, w, h) in faces:\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                roi_gray = gray[y:y + h, x:x + w]\n",
    "                roi_color = frame[y:y + h, x:x + w]\n",
    "                eyes = eye_cascade.detectMultiScale(roi_gray, 1.1, 3)\n",
    "                for (ex, ey, ew, eh) in eyes:\n",
    "                    cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "                mouth = smile_cascade.detectMultiScale(roi_gray, 1.7, 20)\n",
    "                for (lx, ly, lw, lh) in mouth:\n",
    "                    cv2.rectangle(roi_color, (lx, ly), (lx + lw, ly + lh), (0, 0, 255), 2)\n",
    "            y0 = 30\n",
    "            for line in wrapped:\n",
    "                cv2.putText(frame, line, (20, y0), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                y0 += 30\n",
    "\n",
    "            cv2.imshow(\"AI Interview\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF in [ord('q'), 27]:\n",
    "                stop_flag[\"next\"] = True\n",
    "                break\n",
    "\n",
    "        if rec_thread.is_alive():\n",
    "            rec_thread.join(timeout=1.0)\n",
    "\n",
    "        transcription = {\"text\": \"\"}\n",
    "        trans_done_flag = threading.Event()\n",
    "\n",
    "        def _transcribe():\n",
    "            transcription[\"text\"] = transcribe_audio(AUDIO_FILENAME)\n",
    "            trans_done_flag.set()\n",
    "\n",
    "        wt = threading.Thread(target=_transcribe, daemon=True)\n",
    "        wt.start()\n",
    "\n",
    "        while not trans_done_flag.is_set():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                time.sleep(0.01)\n",
    "                continue\n",
    "            cv2.putText(frame, \"Processing answer...\", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "            cv2.imshow(\"AI Interview\", frame)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "        answer_text = transcription[\"text\"]\n",
    "        print(\"Answer:\", answer_text)\n",
    "        all_answers.append(answer_text)\n",
    "\n",
    "        # Generate feedback and speak it\n",
    "        feedback = \"\"\n",
    "        if q_index == 1:\n",
    "            feedback = f\"Nice to meet you, {candidate}.\"\n",
    "        else:\n",
    "            feedback = generate_feedback(current_q, answer_text)\n",
    "\n",
    "        if feedback:\n",
    "            print(\"Feedback:\", feedback)\n",
    "            speak_blocking(feedback)\n",
    "\n",
    "        # Generate next question except if last question\n",
    "        if q_index < total_qs:\n",
    "            next_container = [None]\n",
    "            if q_index == 1 or (2 <= q_index <= 1 + TECH_QUESTIONS - 1):\n",
    "                role = \"Technical\"\n",
    "            else:\n",
    "                role = \"HR\"\n",
    "            generate_next_question_background(jd_summary, resume_text, used, next_container, role)\n",
    "            current_q = next_container[0] or (\"Tell me about a project from your resume.\" if role==\"Technical\" else \"Why do you want to join our company?\")\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"\\nInterview Completed.\")\n",
    "    speak_blocking(f\"Thank you for the interview, {candidate}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_interview()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a991e51-1f39-4a2b-b2cb-0fd6bbdcd215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a329b09b-57b5-4b44-903a-a8d00934badb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instructions:\n",
      "üéôÔ∏è Speak your answers naturally. The system records automatically.\n",
      "‚è±Ô∏è If you stay silent for 10 seconds or press 'q', it moves to next question.\n",
      "üö™ Press 'Esc' anytime to exit.\n",
      "\n",
      "Gemini configured.\n",
      "Loading Whisper model: medium\n",
      "Whisper loaded.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your name:  Mahesh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome Mahesh! Please upload your resume.\n",
      "Resume uploaded.\n",
      "\n",
      "\n",
      "Question 1/10: Introduce yourself.\n",
      "Answer: Good afternoon, this is Mahesh and I am from Warangal.\n",
      "Feedback: \"Good afternoon, Mahesh! Great to have you join us today.\"\n",
      "\n",
      "Question 2/10: Explain how you handled imbalanced data in a previous ML project\n"
     ]
    }
   ],
   "source": [
    "import os, time, queue, re, contextlib, threading, sys\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import cv2, numpy as np\n",
    "\n",
    "try:\n",
    "    import whisper\n",
    "except:\n",
    "    whisper = None\n",
    "\n",
    "try:\n",
    "    import pyttsx3\n",
    "    TTS_AVAILABLE = True\n",
    "except:\n",
    "    pyttsx3 = None\n",
    "    TTS_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "    GEMINI_AVAILABLE = True\n",
    "except:\n",
    "    genai = None\n",
    "    GEMINI_AVAILABLE = False\n",
    "\n",
    "import PyPDF2, docx\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "\n",
    "print(\"Instructions:\")\n",
    "print(\"üéôÔ∏è Speak your answers naturally. The system records automatically.\")\n",
    "print(\"‚è±Ô∏è If you stay silent for 10 seconds or press 'q', it moves to next question.\")\n",
    "print(\"üö™ Press 'Esc' anytime to exit.\\n\")\n",
    "\n",
    "GEMINI_API_KEY = \"AIzaSyB3lGV8ju_l86r5_j465vTsXXW22yqddYY\"\n",
    "GENIE_MODEL_NAME = \"gemini-2.0-flash\"\n",
    "WHISPER_MODEL_NAME = \"medium\"\n",
    "\n",
    "AUDIO_FILENAME = \"candidate_answer.wav\"\n",
    "SAMPLE_RATE = 16000\n",
    "SILENCE_DURATION = 10.0\n",
    "SILENCE_THRESHOLD = 0.01\n",
    "WIN_W, WIN_H = 960, 540\n",
    "\n",
    "MAX_QUESTION_WORDS = 14\n",
    "TECH_QUESTIONS = 6\n",
    "HR_QUESTIONS = 3\n",
    "TOTAL_QUESTIONS = 1 + TECH_QUESTIONS + HR_QUESTIONS\n",
    "GEN_RETRY = 1\n",
    "\n",
    "gen_model = None\n",
    "if GEMINI_AVAILABLE and GEMINI_API_KEY:\n",
    "    try:\n",
    "        genai.configure(api_key=GEMINI_API_KEY)\n",
    "        gen_model = genai.GenerativeModel(GENIE_MODEL_NAME)\n",
    "        print(\"Gemini configured.\")\n",
    "    except Exception as e:\n",
    "        print(\"Gemini init failed:\", e)\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_eye.xml\")\n",
    "smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_smile.xml\")\n",
    "\n",
    "whisper_model = None\n",
    "if whisper:\n",
    "    try:\n",
    "        print(\"Loading Whisper model:\", WHISPER_MODEL_NAME)\n",
    "        whisper_model = whisper.load_model(WHISPER_MODEL_NAME)\n",
    "        print(\"Whisper loaded.\")\n",
    "    except Exception as e:\n",
    "        print(\"Whisper load failed:\", e)\n",
    "\n",
    "def speak_blocking(text):\n",
    "    if not TTS_AVAILABLE:\n",
    "        print(\"AI:\", text)\n",
    "        return\n",
    "    try:\n",
    "        engine = pyttsx3.init()\n",
    "        engine.setProperty('rate', 170)\n",
    "        engine.say(str(text))\n",
    "        engine.runAndWait()\n",
    "    except Exception:\n",
    "        print(\"AI:\", text)\n",
    "\n",
    "def clean_text(t):\n",
    "    if t is None: return \"\"\n",
    "    t = re.sub(r'[^\\x00-\\x7F]+', ' ', str(t))\n",
    "    return re.sub(r'\\s+', ' ', t).strip()\n",
    "\n",
    "def wrap_text(text, max_chars=40):\n",
    "    if not text:\n",
    "        return [\"\"]\n",
    "    words, lines, cur = text.split(), [], \"\"\n",
    "    for w in words:\n",
    "        if len((cur + \" \" + w).strip()) <= max_chars:\n",
    "            cur = (cur + \" \" + w).strip()\n",
    "        else:\n",
    "            lines.append(cur)\n",
    "            cur = w\n",
    "    if cur: lines.append(cur)\n",
    "    return lines\n",
    "\n",
    "def extract_text_from_pdf(path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(path,\"rb\") as f:\n",
    "            r = PyPDF2.PdfReader(f)\n",
    "            for p in r.pages:\n",
    "                text += (p.extract_text() or \"\") + \"\\n\"\n",
    "    except:\n",
    "        pass\n",
    "    return clean_text(text)\n",
    "\n",
    "def extract_text_from_docx(path):\n",
    "    try:\n",
    "        d = docx.Document(path)\n",
    "        return clean_text(\"\\n\".join(p.text for p in d.paragraphs if p.text.strip()))\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def extract_text_from_file(path):\n",
    "    if not path: return \"\"\n",
    "    p = path.lower()\n",
    "    if p.endswith(\".pdf\"): return extract_text_from_pdf(path)\n",
    "    if p.endswith((\".doc\", \".docx\")): return extract_text_from_docx(path)\n",
    "    return \"\"\n",
    "\n",
    "def record_audio(stop_flag, filename=AUDIO_FILENAME):\n",
    "    q_audio, frames = queue.Queue(), []\n",
    "    last_loud = time.time()\n",
    "    speech_started = False\n",
    "\n",
    "    def _cb(indata, frames_count, time_info, status):\n",
    "        q_audio.put(indata.copy())\n",
    "\n",
    "    try:\n",
    "        with sd.InputStream(samplerate=SAMPLE_RATE, channels=1, callback=_cb):\n",
    "            while not stop_flag[\"next\"]:\n",
    "                try:\n",
    "                    data = q_audio.get(timeout=0.05)\n",
    "                    frames.append(data)\n",
    "                    rms = np.sqrt(np.mean(data**2))\n",
    "                    if rms > SILENCE_THRESHOLD:\n",
    "                        speech_started = True\n",
    "                        last_loud = time.time()\n",
    "                    elif speech_started and (time.time() - last_loud) > SILENCE_DURATION:\n",
    "                        stop_flag[\"next\"] = True\n",
    "                except queue.Empty:\n",
    "                    continue\n",
    "    except Exception as e:\n",
    "        print(\"Audio issue:\", e)\n",
    "\n",
    "    if frames:\n",
    "        audio = np.concatenate(frames, axis=0).flatten()\n",
    "        audio /= (np.max(np.abs(audio)) + 1e-9)\n",
    "        write(filename, SAMPLE_RATE, (audio * 32767).astype(np.int16))\n",
    "\n",
    "def transcribe_audio(filename=AUDIO_FILENAME):\n",
    "    if whisper_model is None or not os.path.exists(filename):\n",
    "        return \"\"\n",
    "    with contextlib.redirect_stdout(None):\n",
    "        try:\n",
    "            r = whisper_model.transcribe(filename, fp16=False, language=\"en\")\n",
    "            return clean_text(r.get(\"text\", \"\"))\n",
    "        except Exception as e:\n",
    "            print(\"Whisper error:\", e)\n",
    "            return \"\"\n",
    "\n",
    "def generate_next_question_background(jd_summary, resume_text, used_set, container, role):\n",
    "    jd_short = jd_summary if len(jd_summary) <= 800 else jd_summary[:800] + \"...\"\n",
    "    resume_short = resume_text if len(resume_text) <= 1200 else resume_text[:1200] + \"...\"\n",
    "    prompt = (\n",
    "        f\"Generate ONE {role} interview question (max {MAX_QUESTION_WORDS} words). \"\n",
    "        f\"JD: {jd_short}. Resume: {resume_short}. \"\n",
    "        f\"Only output the question. Avoid repeated or nonsensical questions. \"\n",
    "        f\"Previous questions: {list(used_set)}.\"\n",
    "    )\n",
    "    if gen_model is None:\n",
    "        container[0] = None\n",
    "        return\n",
    "    for _ in range(GEN_RETRY):\n",
    "        try:\n",
    "            r = gen_model.generate_content(prompt)\n",
    "            q = clean_text(r.text.split(\"\\n\")[0])\n",
    "            q = re.sub(r'^(question\\s*(\\d*|once|for you)\\s*[:\\-]?)', '', q, flags=re.I).strip()\n",
    "            q = q.split('.')[0].strip()\n",
    "            if q and q not in used_set:\n",
    "                used_set.add(q)\n",
    "                container[0] = q\n",
    "                return\n",
    "        except:\n",
    "            time.sleep(0.4)\n",
    "    container[0] = None\n",
    "\n",
    "def generate_feedback(question, answer):\n",
    "    if not gen_model:\n",
    "        return f\"Thank you for your answer.\"\n",
    "    prompt = (\n",
    "        f\"Provide a brief positive feedback or encouragement (max 20 words) \"\n",
    "        f\"on this answer: '{answer}' \"\n",
    "        f\"for the question: '{question}'. \"\n",
    "        f\"Avoid negative comments. Only output the feedback.\"\n",
    "    )\n",
    "    try:\n",
    "        r = gen_model.generate_content(prompt)\n",
    "        fb = clean_text(r.text.split(\"\\n\")[0])\n",
    "        return fb or \"Thank you for your answer.\"\n",
    "    except:\n",
    "        return \"Thank you for your answer.\"\n",
    "\n",
    "def generate_first_answer_feedback(candidate_name, candidate_answer):\n",
    "    if not gen_model:\n",
    "        return f\"Nice to meet you, {candidate_name}.\"\n",
    "    prompt = (\n",
    "        f\"You are an AI assistant. The candidate said: '{candidate_answer}'. \"\n",
    "        f\"Generate a warm, friendly, and natural greeting response including their name {candidate_name}. \"\n",
    "        f\"Do NOT be generic. Keep it brief and positive.\"\n",
    "    )\n",
    "    try:\n",
    "        r = gen_model.generate_content(prompt)\n",
    "        reply = clean_text(r.text.split(\"\\n\")[0])\n",
    "        return reply or f\"Nice to meet you, {candidate_name}.\"\n",
    "    except:\n",
    "        return f\"Nice to meet you, {candidate_name}.\"\n",
    "\n",
    "def run_interview():\n",
    "    candidate = input(\"Enter your name: \").strip() or \"Candidate\"\n",
    "    print(f\"\\nWelcome {candidate}! Please upload your resume.\")\n",
    "    speak_blocking(\"Please upload your resume.\")\n",
    "    Tk().withdraw()\n",
    "    resume_path = askopenfilename(title=\"Select Resume\", filetypes=[(\"Documents\",\"*.pdf *.docx\")])\n",
    "    resume_text = extract_text_from_file(resume_path) if resume_path else \"\"\n",
    "    print(\"Resume uploaded.\\n\")\n",
    "\n",
    "    jd_summary = (\n",
    "        \"We are looking for a motivated AI/ML Engineer with 1‚Äì3 years of hands-on experience \"\n",
    "        \"in building and deploying machine learning models.\"\n",
    "    )\n",
    "\n",
    "    used = set()\n",
    "    current_q = \"Introduce yourself.\"\n",
    "    used.add(current_q)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open webcam.\")\n",
    "        return\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "    cv2.namedWindow(\"AI Interview\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"AI Interview\", WIN_W, WIN_H)\n",
    "\n",
    "    all_answers = []\n",
    "\n",
    "    total_qs = TOTAL_QUESTIONS\n",
    "\n",
    "    for q_index in range(1, total_qs + 1):\n",
    "        print(f\"\\nQuestion {q_index}/{total_qs}: {current_q}\")\n",
    "        speak_blocking(f\"Question {q_index}. {current_q}\")\n",
    "\n",
    "        stop_flag = {\"next\": False}\n",
    "        rec_thread = threading.Thread(target=record_audio, args=(stop_flag,), daemon=True)\n",
    "        rec_thread.start()\n",
    "\n",
    "        wrapped = wrap_text(current_q, 40)\n",
    "\n",
    "        while not stop_flag[\"next\"]:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                time.sleep(0.01)\n",
    "                continue\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "            for (x, y, w, h) in faces:\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                roi_gray = gray[y:y + h, x:x + w]\n",
    "                roi_color = frame[y:y + h, x:x + w]\n",
    "                eyes = eye_cascade.detectMultiScale(roi_gray, 1.1, 3)\n",
    "                for (ex, ey, ew, eh) in eyes:\n",
    "                    cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "                mouth = smile_cascade.detectMultiScale(roi_gray, 1.7, 20)\n",
    "                for (lx, ly, lw, lh) in mouth:\n",
    "                    cv2.rectangle(roi_color, (lx, ly), (lx + lw, ly + lh), (0, 0, 255), 2)\n",
    "            y0 = 30\n",
    "            for line in wrapped:\n",
    "                cv2.putText(frame, line, (20, y0), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                y0 += 30\n",
    "            cv2.imshow(\"AI Interview\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF in [ord('q'), 27]:\n",
    "                stop_flag[\"next\"] = True\n",
    "                break\n",
    "\n",
    "        if rec_thread.is_alive():\n",
    "            rec_thread.join(timeout=1.0)\n",
    "\n",
    "        transcription = {\"text\": \"\"}\n",
    "        trans_done_flag = threading.Event()\n",
    "\n",
    "        def _transcribe():\n",
    "            transcription[\"text\"] = transcribe_audio(AUDIO_FILENAME)\n",
    "            trans_done_flag.set()\n",
    "\n",
    "        wt = threading.Thread(target=_transcribe, daemon=True)\n",
    "        wt.start()\n",
    "\n",
    "        while not trans_done_flag.is_set():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                time.sleep(0.01)\n",
    "                continue\n",
    "            cv2.putText(frame, \"Processing answer...\", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "            cv2.imshow(\"AI Interview\", frame)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "        answer_text = transcription[\"text\"]\n",
    "        print(\"Answer:\", answer_text)\n",
    "        all_answers.append(answer_text)\n",
    "\n",
    "        # Generate dynamic AI feedback\n",
    "        if q_index == 1:\n",
    "            feedback = generate_first_answer_feedback(candidate, answer_text)\n",
    "        else:\n",
    "            feedback = generate_feedback(current_q, answer_text)\n",
    "        if feedback:\n",
    "            print(\"Feedback:\", feedback)\n",
    "            speak_blocking(feedback)\n",
    "\n",
    "        # Generate next question except if last question\n",
    "        if q_index < total_qs:\n",
    "            next_container = [None]\n",
    "            if q_index == 1 or (2 <= q_index <= 1 + TECH_QUESTIONS - 1):\n",
    "                role = \"Technical\"\n",
    "            else:\n",
    "                role = \"HR\"\n",
    "            generate_next_question_background(jd_summary, resume_text, used, next_container, role)\n",
    "            current_q = next_container[0] or (\"Tell me about a project from your resume.\" if role==\"Technical\" else \"Why do you want to join our company?\")\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"\\nInterview Completed.\")\n",
    "    speak_blocking(f\"Thank you for the interview, {candidate}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_interview()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7482f32a-3200-4506-b57e-ea849befbff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1897dca-77d8-488b-a6dc-434953b161b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac7c699-ac2e-4660-93c4-1ac97e0b9b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee62ff3-f63d-4b40-9791-0618b3bf1298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= AI INTERVIEW SYSTEM =================\n",
    "# - Keeps webcam live while long tasks run\n",
    "# - Feedback always spoken BEFORE next question generation\n",
    "# - Next question is NOT spoken at the end of previous loop (prevents duplicate)\n",
    "# - Uses background threads for transcription / generation / TTS\n",
    "# ======================================================\n",
    "\n",
    "import os\n",
    "import time\n",
    "import queue\n",
    "import re\n",
    "import contextlib\n",
    "import threading\n",
    "import sys\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import cv2\n",
    "import numpy as np\n",
    "# ---------------- optional libraries ----------------\n",
    "try:\n",
    "    import whisper\n",
    "except:\n",
    "    whisper = None\n",
    "\n",
    "try:\n",
    "    import pyttsx3\n",
    "    TTS_AVAILABLE = True\n",
    "except:\n",
    "    pyttsx3 = None\n",
    "    TTS_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "    GEMINI_AVAILABLE = True\n",
    "except:\n",
    "    genai = None\n",
    "    GEMINI_AVAILABLE = False\n",
    "\n",
    "\n",
    "import PyPDF2\n",
    "import docx\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "\n",
    "# ---------------- basic instructions ----------------\n",
    "print(\"Instructions:\")\n",
    "print(\"üéôÔ∏è Speak your answers naturally. The system records automatically.\")\n",
    "print(\"‚è±Ô∏è If you stay silent for 10 seconds or press 'q', it moves to next question.\")\n",
    "print(\"üö™ Press 'Esc' anytime to exit.\\n\")\n",
    "\n",
    "# ---------------- config values ----------------\n",
    "GEMINI_API_KEY = \"AIzaSyB3lGV8ju_l86r5_j465vTsXXW22yqddYY\"\n",
    "GENIE_MODEL_NAME = \"gemini-2.0-flash\"\n",
    "WHISPER_MODEL_NAME = \"medium\"\n",
    "\n",
    "AUDIO_FILENAME = \"candidate_answer.wav\"\n",
    "SAMPLE_RATE = 16000\n",
    "SILENCE_DURATION = 10.0\n",
    "SILENCE_THRESHOLD = 0.01\n",
    "WIN_W, WIN_H = 960, 540\n",
    "\n",
    "MAX_QUESTION_WORDS = 14\n",
    "TECH_QUESTIONS = 6\n",
    "HR_QUESTIONS = 3\n",
    "TOTAL_QUESTIONS = 1 + TECH_QUESTIONS + HR_QUESTIONS\n",
    "GEN_RETRY = 1\n",
    "\n",
    "# ---------------- init gemini (if available) ----------------\n",
    "gen_model = None\n",
    "if GEMINI_AVAILABLE and GEMINI_API_KEY:\n",
    "    try:\n",
    "        genai.configure(api_key=GEMINI_API_KEY)\n",
    "        gen_model = genai.GenerativeModel(GENIE_MODEL_NAME)\n",
    "        print(\"Gemini configured.\")\n",
    "    except Exception as e:\n",
    "        print(\"Gemini init failed:\", e)\n",
    "\n",
    "# ---------------- load CV cascades ----------------\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_eye.xml\")\n",
    "smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_smile.xml\")\n",
    "\n",
    "# ---------------- load whisper ----------------\n",
    "whisper_model = None\n",
    "if whisper:\n",
    "    try:\n",
    "        print(\"Loading Whisper model:\", WHISPER_MODEL_NAME)\n",
    "        whisper_model = whisper.load_model(WHISPER_MODEL_NAME)\n",
    "        print(\"Whisper loaded.\")\n",
    "    except Exception as e:\n",
    "        print(\"Whisper load failed:\", e)\n",
    "\n",
    "# ---------------- blocking TTS (used only at startup / final thank you) ----------------\n",
    "def speak_blocking(text):\n",
    "    \"\"\"Speak text using pyttsx3, blocking until finished.\"\"\"\n",
    "    if not TTS_AVAILABLE:\n",
    "        print(\"AI:\", text)\n",
    "        return\n",
    "    try:\n",
    "        engine = pyttsx3.init()\n",
    "        engine.setProperty('rate', 170)\n",
    "        engine.say(str(text))\n",
    "        engine.runAndWait()\n",
    "    except Exception:\n",
    "        print(\"AI:\", text)\n",
    "\n",
    "# ---------------- non-blocking TTS with completion Event ----------------\n",
    "def speak_async(text):\n",
    "    \"\"\"\n",
    "    Speak text in a background thread and return a threading.Event()\n",
    "    which will be set when speaking finishes. If TTS not available the\n",
    "    event is set immediately (and it prints).\n",
    "    \"\"\"\n",
    "    done = threading.Event()\n",
    "\n",
    "    if not TTS_AVAILABLE:\n",
    "        print(\"AI (no TTS):\", text)\n",
    "        done.set()\n",
    "        return done\n",
    "\n",
    "    def _run():\n",
    "        try:\n",
    "            engine = pyttsx3.init()\n",
    "            engine.setProperty('rate', 170)\n",
    "            engine.say(str(text))\n",
    "            engine.runAndWait()\n",
    "        except Exception:\n",
    "            print(\"AI:\", text)\n",
    "        finally:\n",
    "            done.set()\n",
    "\n",
    "    threading.Thread(target=_run, daemon=True).start()\n",
    "    return done\n",
    "\n",
    "# ---------------- text cleanup & wrapping ----------------\n",
    "def clean_text(t):\n",
    "    if t is None:\n",
    "        return \"\"\n",
    "    t = re.sub(r'[^\\x00-\\x7F]+', ' ', str(t))\n",
    "    return re.sub(r'\\s+', ' ', t).strip()\n",
    "\n",
    "def wrap_text(text, max_chars=40):\n",
    "    \"\"\"Wrap text for display on webcam.\"\"\"\n",
    "    if not text:\n",
    "        return [\"\"]\n",
    "    words, lines, cur = text.split(), [], \"\"\n",
    "    for w in words:\n",
    "        if len((cur + \" \" + w).strip()) <= max_chars:\n",
    "            cur = (cur + \" \" + w).strip()\n",
    "        else:\n",
    "            lines.append(cur)\n",
    "            cur = w\n",
    "    if cur:\n",
    "        lines.append(cur)\n",
    "    return lines\n",
    "\n",
    "# ---------------- resume extraction ----------------\n",
    "def extract_text_from_pdf(path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            r = PyPDF2.PdfReader(f)\n",
    "            for p in r.pages:\n",
    "                text += (p.extract_text() or \"\") + \"\\n\"\n",
    "    except Exception:\n",
    "        pass\n",
    "    return clean_text(text)\n",
    "\n",
    "def extract_text_from_docx(path):\n",
    "    try:\n",
    "        d = docx.Document(path)\n",
    "        return clean_text(\"\\n\".join(p.text for p in d.paragraphs if p.text.strip()))\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def extract_text_from_file(path):\n",
    "    if not path:\n",
    "        return \"\"\n",
    "    p = path.lower()\n",
    "    if p.endswith(\".pdf\"):\n",
    "        return extract_text_from_pdf(path)\n",
    "    if p.endswith((\".doc\", \".docx\")):\n",
    "        return extract_text_from_docx(path)\n",
    "    return \"\"\n",
    "\n",
    "# ---------------- audio recording ----------------\n",
    "def record_audio(stop_flag, filename=AUDIO_FILENAME):\n",
    "    \"\"\"\n",
    "    Record audio from microphone until silence (SILENCE_DURATION) after speech started,\n",
    "    or until stop_flag['next'] becomes True (user pressed q).\n",
    "    Saves file to 'filename'.\n",
    "    \"\"\"\n",
    "    q_audio = queue.Queue()\n",
    "    frames = []\n",
    "    last_loud = time.time()\n",
    "    speech_started = False\n",
    "\n",
    "    def _cb(indata, frames_count, time_info, status):\n",
    "        q_audio.put(indata.copy())\n",
    "\n",
    "    try:\n",
    "        with sd.InputStream(samplerate=SAMPLE_RATE, channels=1, callback=_cb):\n",
    "            while not stop_flag[\"next\"]:\n",
    "                try:\n",
    "                    data = q_audio.get(timeout=0.05)\n",
    "                    frames.append(data)\n",
    "                    rms = np.sqrt(np.mean(data**2))\n",
    "                    if rms > SILENCE_THRESHOLD:\n",
    "                        speech_started = True\n",
    "                        last_loud = time.time()\n",
    "                    elif speech_started and (time.time() - last_loud) > SILENCE_DURATION:\n",
    "                        stop_flag[\"next\"] = True\n",
    "                except queue.Empty:\n",
    "                    continue\n",
    "    except Exception as e:\n",
    "        print(\"Audio issue:\", e)\n",
    "\n",
    "    if frames:\n",
    "        audio = np.concatenate(frames, axis=0).flatten()\n",
    "        audio /= (np.max(np.abs(audio)) + 1e-9)\n",
    "        write(filename, SAMPLE_RATE, (audio * 32767).astype(np.int16))\n",
    "\n",
    "# ---------------- transcription ----------------\n",
    "def transcribe_audio(filename=AUDIO_FILENAME):\n",
    "    \"\"\"Use Whisper to transcribe or return empty string if not available.\"\"\"\n",
    "    if whisper_model is None or not os.path.exists(filename):\n",
    "        return \"\"\n",
    "    # suppress whisper printing to stdout\n",
    "    with contextlib.redirect_stdout(None):\n",
    "        try:\n",
    "            r = whisper_model.transcribe(filename, fp16=False, language=\"en\")\n",
    "            return clean_text(r.get(\"text\", \"\"))\n",
    "        except Exception as e:\n",
    "            print(\"Whisper error:\", e)\n",
    "            return \"\"\n",
    "\n",
    "# ---------------- gemini helpers ----------------\n",
    "def generate_next_question_background(jd_summary, resume_text, used_set, container, role):\n",
    "    \"\"\"Generate a single next question using Gemini (stores in container[0] or None).\"\"\"\n",
    "    jd_short = jd_summary if len(jd_summary) <= 800 else jd_summary[:800] + \"...\"\n",
    "    resume_short = resume_text if len(resume_text) <= 1200 else resume_text[:1200] + \"...\"\n",
    "    prompt = (\n",
    "        f\"Generate ONE {role} interview question (max {MAX_QUESTION_WORDS} words). \"\n",
    "        f\"JD: {jd_short}. Resume: {resume_short}. \"\n",
    "        f\"Only output the question. Avoid repeated or nonsensical questions. \"\n",
    "        f\"Previous questions: {list(used_set)}.\"\n",
    "    )\n",
    "    if gen_model is None:\n",
    "        container[0] = None\n",
    "        return\n",
    "    for _ in range(GEN_RETRY):\n",
    "        try:\n",
    "            r = gen_model.generate_content(prompt)\n",
    "            q = clean_text(r.text.split(\"\\n\")[0])\n",
    "            q = re.sub(r'^(question\\s*\\d*[:\\-]?)', '', q, flags=re.I).strip()\n",
    "            q = q.split('.')[0].strip()\n",
    "            if q and q not in used_set:\n",
    "                used_set.add(q)\n",
    "                container[0] = q\n",
    "                return\n",
    "        except Exception:\n",
    "            time.sleep(0.4)\n",
    "    container[0] = None\n",
    "\n",
    "def generate_feedback(question, answer):\n",
    "    \"\"\"Generate a short positive feedback for an answer using Gemini.\"\"\"\n",
    "    if not gen_model:\n",
    "        return \"Thank you for your answer.\"\n",
    "    prompt = (\n",
    "        f\"Provide a brief positive feedback or encouragement (max 20 words) \"\n",
    "        f\"on this answer: '{answer}' \"\n",
    "        f\"for the question: '{question}'. \"\n",
    "        f\"Avoid negative comments. Only output the feedback.\"\n",
    "    )\n",
    "    try:\n",
    "        r = gen_model.generate_content(prompt)\n",
    "        fb = clean_text(r.text.split(\"\\n\")[0])\n",
    "        return fb or \"Thank you for your answer.\"\n",
    "    except Exception:\n",
    "        return \"Thank you for your answer.\"\n",
    "\n",
    "def generate_first_answer_feedback(candidate_name, candidate_answer):\n",
    "    \"\"\"Generate warm greeting feedback for the first answer (introduction).\"\"\"\n",
    "    if not gen_model:\n",
    "        return f\"Nice to meet you, {candidate_name}.\"\n",
    "    prompt = (\n",
    "        f\"You are an AI assistant. The candidate said: '{candidate_answer}'. \"\n",
    "        f\"Generate a warm, friendly, and natural greeting response including their name {candidate_name}. \"\n",
    "        f\"Do NOT be generic. Keep it brief and positive.\"\n",
    "    )\n",
    "    try:\n",
    "        r = gen_model.generate_content(prompt)\n",
    "        reply = clean_text(r.text.split(\"\\n\")[0])\n",
    "        return reply or f\"Nice to meet you, {candidate_name}.\"\n",
    "    except Exception:\n",
    "        return f\"Nice to meet you, {candidate_name}.\"\n",
    "\n",
    "# ================= main interview flow =================\n",
    "def run_interview():\n",
    "    # ---------------- candidate + resume ----------------\n",
    "    candidate = input(\"Enter your name: \").strip() or \"Candidate\"\n",
    "    print(f\"\\nWelcome {candidate}! Please upload your resume.\")\n",
    "    # initial prompt ‚Äî small blocking call is acceptable\n",
    "    speak_blocking(\"Please upload your resume.\")\n",
    "    Tk().withdraw()\n",
    "    resume_path = askopenfilename(title=\"Select Resume\", filetypes=[(\"Documents\",\"*.pdf *.docx\")])\n",
    "    resume_text = extract_text_from_file(resume_path) if resume_path else \"\"\n",
    "    print(\"Resume uploaded.\\n\")\n",
    "\n",
    "    # example JD ‚Äî can be replaced with user input\n",
    "    jd_summary = (\n",
    "        \"We are looking for full-stack developer and skills required: Java and SQL.\"\n",
    "    )\n",
    "\n",
    "    used = set()\n",
    "    current_q = \"Introduce yourself.\"\n",
    "    used.add(current_q)\n",
    "\n",
    "    # ---------------- camera setup ----------------\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open webcam.\")\n",
    "        return\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "    cv2.namedWindow(\"AI Interview\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"AI Interview\", WIN_W, WIN_H)\n",
    "\n",
    "    all_answers = []\n",
    "    total_qs = TOTAL_QUESTIONS\n",
    "\n",
    "    try:\n",
    "        for q_index in range(1, total_qs + 1):\n",
    "            # ---------------- speak the question at the start of iteration ----------------\n",
    "            print(f\"\\nQuestion {q_index}/{total_qs}: {current_q}\")\n",
    "            # Speak the question (non-blocking) and wait while keeping webcam live\n",
    "            q_speak_evt = speak_async(f\"Question {q_index}. {current_q}\")\n",
    "            # Display the question while it's being spoken\n",
    "            while not q_speak_evt.is_set():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    time.sleep(0.01)\n",
    "                    continue\n",
    "                wrapped = wrap_text(current_q, 40)\n",
    "                y0 = 30\n",
    "                for line in wrapped:\n",
    "                    cv2.putText(frame, line, (20, y0), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                    y0 += 30\n",
    "                cv2.putText(frame, \"Listening shortly... (press 'q' to skip)\", (20, WIN_H - 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)\n",
    "                cv2.imshow(\"AI Interview\", frame)\n",
    "                if cv2.waitKey(1) & 0xFF in [ord('q'), 27]:\n",
    "                    # allow user to skip speaking\n",
    "                    break\n",
    "\n",
    "            # ---------------- recording ----------------\n",
    "            stop_flag = {\"next\": False}\n",
    "            rec_thread = threading.Thread(target=record_audio, args=(stop_flag,), daemon=True)\n",
    "            rec_thread.start()\n",
    "\n",
    "            wrapped = wrap_text(current_q, 40)\n",
    "\n",
    "            # keep camera alive while recording\n",
    "            while not stop_flag[\"next\"]:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    time.sleep(0.01)\n",
    "                    continue\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "                for (x, y, w, h) in faces:\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                    roi_gray = gray[y:y + h, x:x + w]\n",
    "                    roi_color = frame[y:y + h, x:x + w]\n",
    "                    eyes = eye_cascade.detectMultiScale(roi_gray, 1.1, 3)\n",
    "                    for (ex, ey, ew, eh) in eyes:\n",
    "                        cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "                    mouth = smile_cascade.detectMultiScale(roi_gray, 1.7, 20)\n",
    "                    for (lx, ly, lw, lh) in mouth:\n",
    "                        cv2.rectangle(roi_color, (lx, ly), (lx + lw, ly + lh), (0, 0, 255), 2)\n",
    "                y0 = 30\n",
    "                for line in wrapped:\n",
    "                    cv2.putText(frame, line, (20, y0), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                    y0 += 30\n",
    "                cv2.putText(frame, \"Recording... (press 'q' to stop)\", (20, WIN_H - 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1)\n",
    "                cv2.imshow(\"AI Interview\", frame)\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key in [ord('q'), 27]:\n",
    "                    stop_flag[\"next\"] = True\n",
    "                    break\n",
    "\n",
    "            # ensure recording thread finishes saving file\n",
    "            if rec_thread.is_alive():\n",
    "                rec_thread.join(timeout=1.0)\n",
    "\n",
    "            # ---------------- transcription (background) ----------------\n",
    "            transcription = {\"text\": \"\"}\n",
    "            trans_done_flag = threading.Event()\n",
    "\n",
    "            def _transcribe():\n",
    "                transcription[\"text\"] = transcribe_audio(AUDIO_FILENAME)\n",
    "                trans_done_flag.set()\n",
    "\n",
    "            wt = threading.Thread(target=_transcribe, daemon=True)\n",
    "            wt.start()\n",
    "\n",
    "            while not trans_done_flag.is_set():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    time.sleep(0.01)\n",
    "                    continue\n",
    "                cv2.putText(frame, \"Processing answer...\", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "                cv2.imshow(\"AI Interview\", frame)\n",
    "                if cv2.waitKey(1) & 0xFF == 27:\n",
    "                    break\n",
    "\n",
    "            answer_text = transcription[\"text\"]\n",
    "            print(\"Answer:\", answer_text)\n",
    "            all_answers.append(answer_text)\n",
    "\n",
    "            # ---------------- generate feedback (background) ----------------\n",
    "            fb_container = [None]\n",
    "            fb_done = threading.Event()\n",
    "\n",
    "            def _gen_feedback():\n",
    "                try:\n",
    "                    if q_index == 1:\n",
    "                        fb = generate_first_answer_feedback(candidate, answer_text)\n",
    "                    else:\n",
    "                        fb = generate_feedback(current_q, answer_text)\n",
    "                    fb_container[0] = fb\n",
    "                except Exception as e:\n",
    "                    print(\"Feedback generation error:\", e)\n",
    "                    fb_container[0] = \"Thank you for your answer.\"\n",
    "                finally:\n",
    "                    fb_done.set()\n",
    "\n",
    "            threading.Thread(target=_gen_feedback, daemon=True).start()\n",
    "\n",
    "            # keep camera alive while feedback generated\n",
    "            while not fb_done.is_set():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    time.sleep(0.01)\n",
    "                    continue\n",
    "                cv2.putText(frame, \"Generating feedback...\", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 200, 200), 2)\n",
    "                cv2.imshow(\"AI Interview\", frame)\n",
    "                if cv2.waitKey(1) & 0xFF == 27:\n",
    "                    break\n",
    "\n",
    "            feedback = fb_container[0] or \"Thank you for your answer.\"\n",
    "            print(\"Feedback:\", feedback)\n",
    "\n",
    "            # ---------------- speak feedback (non-blocking) and wait while keeping webcam live ----------------\n",
    "            speak_evt = speak_async(feedback)\n",
    "            while not speak_evt.is_set():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    time.sleep(0.01)\n",
    "                    continue\n",
    "                cv2.putText(frame, \"Speaking feedback...\", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (180, 180, 255), 2)\n",
    "                cv2.imshow(\"AI Interview\", frame)\n",
    "                if cv2.waitKey(1) & 0xFF == 27:\n",
    "                    break\n",
    "\n",
    "            # ---------------- generate next question AFTER feedback is spoken ----------------\n",
    "            if q_index < total_qs:\n",
    "                next_container = [None]\n",
    "                nq_done = threading.Event()\n",
    "\n",
    "                def _gen_nextq():\n",
    "                    try:\n",
    "                        if q_index == 1 or (2 <= q_index <= 1 + TECH_QUESTIONS - 1):\n",
    "                            role = \"Technical\"\n",
    "                        else:\n",
    "                            role = \"HR\"\n",
    "                        generate_next_question_background(jd_summary, resume_text, used, next_container, role)\n",
    "                    except Exception as e:\n",
    "                        print(\"Next question error:\", e)\n",
    "                    finally:\n",
    "                        nq_done.set()\n",
    "\n",
    "                threading.Thread(target=_gen_nextq, daemon=True).start()\n",
    "\n",
    "                # keep camera alive while next question is being generated\n",
    "                while not nq_done.is_set():\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        time.sleep(0.01)\n",
    "                        continue\n",
    "                    cv2.putText(frame, \"Preparing next question...\", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (200, 200, 100), 2)\n",
    "                    cv2.imshow(\"AI Interview\", frame)\n",
    "                    if cv2.waitKey(1) & 0xFF == 27:\n",
    "                        break\n",
    "\n",
    "                # set current_q to generated or fallback; do NOT speak it here (prevents duplicate)\n",
    "                if q_index == 1 or (2 <= q_index <= 1 + TECH_QUESTIONS - 1):\n",
    "                    role_for_fallback = \"Technical\"\n",
    "                else:\n",
    "                    role_for_fallback = \"HR\"\n",
    "\n",
    "                current_q = next_container[0] or (\n",
    "                    \"Tell me about a project from your resume.\" if role_for_fallback == \"Technical\"\n",
    "                    else \"Why do you want to join our company?\"\n",
    "                )\n",
    "\n",
    "                # mark used (so gemini avoids repeats)\n",
    "                if current_q not in used:\n",
    "                    used.add(current_q)\n",
    "\n",
    "            # ---------------- else: if last question, nothing to prepare ----------------\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        # end for loop\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    print(\"\\nInterview Completed.\")\n",
    "    # final thank-you can be blocking\n",
    "    speak_blocking(f\"Thank you for the interview, {candidate}.\")\n",
    "\n",
    "# ---------------- run ----------------\n",
    "if __name__ == \"__main__\":\n",
    "    run_interview()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15102b3c-24a2-4fa5-8a65-c445ee31cf03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ae144b-e524-472b-9871-9227aee7a0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be790862-620d-432b-b6ff-8917efca66fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57658c21-491a-4c0e-a613-c2bde0e1051a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee4dca2-c045-4dfd-803d-2f4bff8c4503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b458e656-6528-4a24-b755-1c2e457311a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
